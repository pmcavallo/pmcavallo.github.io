name: GitHub Traffic — Daily Snapshots + Friday Weekly Aggregate

on:
  schedule:
    - cron: "5 12 * * *"   # daily @ 12:05 UTC (~07:05 CT)
  workflow_dispatch:

concurrency:
  group: traffic-data
  cancel-in-progress: false

permissions:
  contents: write

env:
  OWNER: pmcavallo
  REPO: pmcavallo.github.io
  GH_TOKEN: ${{ secrets.GH_TOKEN }}

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # ---------- DAILY (always) ----------
      - name: Fetch traffic JSON snapshots
        run: |
          d=$(date -u +%Y-%m-%d)
          mkdir -p "traffic/daily/$d"
          curl -s -H "Authorization: token $GH_TOKEN" -H "Accept: application/vnd.github+json" "https://api.github.com/repos/$OWNER/$REPO/traffic/views" > "traffic/daily/$d/views.json"
          curl -s -H "Authorization: token $GH_TOKEN" -H "Accept: application/vnd.github+json" "https://api.github.com/repos/$OWNER/$REPO/traffic/clones" > "traffic/daily/$d/clones.json"
          curl -s -H "Authorization: token $GH_TOKEN" -H "Accept: application/vnd.github+json" "https://api.github.com/repos/$OWNER/$REPO/traffic/popular/paths" > "traffic/daily/$d/popular_paths.json"
          curl -s -H "Authorization: token $GH_TOKEN" -H "Accept: application/vnd.github+json" "https://api.github.com/repos/$OWNER/$REPO/traffic/popular/referrers" > "traffic/daily/$d/popular_referrers.json"

      - name: Commit daily snapshots (no Pages rebuild)
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          # [skip ci] prevents *new* workflows (incl. Pages) from running on this commit
          commit_message: "traffic: daily snapshot [skip ci]"
          file_pattern: traffic/daily/**

      # ---------- WEEKLY (Fridays only or manual) ----------
      - name: Is Friday?
        id: dow
        run: echo "fri=$([ $(date -u +%u) -eq 5 ] && echo true || echo false)" >> $GITHUB_OUTPUT

      - name: Build weekly aggregate (last 7 days)
        if: ${{ github.event_name == 'workflow_dispatch' || steps.dow.outputs.fri == 'true' }}
        run: |
          python - <<'PY'
          import json, datetime, urllib.request, os, csv
          owner = os.environ["OWNER"]; repo = os.environ["REPO"]; token = os.environ["GH_TOKEN"]
          hdrs = {"Authorization": f"token {token}", "Accept": "application/vnd.github+json", "User-Agent":"gh-traffic-aggregator"}
          def gh(path):
              req = urllib.request.Request(f"https://api.github.com/repos/{owner}/{repo}/traffic/{path}", headers=hdrs)
              with urllib.request.urlopen(req) as r: return json.load(r)
          views = gh("views"); clones = gh("clones"); paths = gh("popular/paths"); refs = gh("popular/referrers")
          today = datetime.datetime.utcnow().date(); start = today - datetime.timedelta(days=6)
          def in_range(ts):
              d = datetime.datetime.fromisoformat(ts.replace('Z','+00:00')).date()
              return start <= d <= today
          v_counts = [x["count"] for x in views.get("views",[]) if in_range(x["timestamp"])]
          v_uniqs  = [x["uniques"] for x in views.get("views",[]) if in_range(x["timestamp"])]
          c_counts = [x["count"] for x in clones.get("clones",[]) if in_range(x["timestamp"])]
          c_uniqs  = [x["uniques"] for x in clones.get("clones",[]) if in_range(x["timestamp"])]
          out = {
              "repo": repo,
              "week_start": start.isoformat(),
              "week_end": today.isoformat(),
              "generated_at_utc": datetime.datetime.utcnow().isoformat(timespec="seconds")+"Z",
              "views_count": int(sum(v_counts)),
              "views_uniques": int(sum(v_uniqs)),
              "clones_count": int(sum(c_counts)),
              "clones_uniques": int(sum(c_uniqs)),
              "top_paths": paths,
              "top_referrers": refs
          }
          os.makedirs("traffic/weekly", exist_ok=True)
          with open("traffic/weekly/latest.json","w") as f: json.dump(out,f,indent=2)
          with open(f"traffic/weekly/week-{start.isoformat()}-to-{today.isoformat()}.json","w") as f: json.dump(out,f,indent=2)

          days = (today - start).days + 1
          avV = round(out["views_count"]/days, 2) if days else 0.0
          avC = round(out["clones_count"]/days, 2) if days else 0.0

          md = []
          md.append(f"### GitHub Weekly Traffic ({out['week_start']} to {out['week_end']})")
          md.append(f"- Views: **{out['views_count']}** (avg **{avV}/day**)  |  Uniques (sum of daily): **{out['views_uniques']}**")
          md.append(f"- Clones: **{out['clones_count']}** (avg **{avC}/day**)  |  Uniques (sum of daily): **{out['clones_uniques']}**")
          def top_lines(items, kind):
              rows = []
              for x in items[:5]:
                  rows.append((f"  - `{x['path']}` — {x['count']} (uniq {x['uniques']})") if kind=="path"
                              else (f"  - {x['referrer']} — {x['count']} (uniq {x['uniques']})"))
              return rows or ["  - (no data)"]
          md.append("**Top referrers**:"); md.extend(top_lines(out["top_referrers"], "ref"))
          md.append("**Top paths**:");     md.extend(top_lines(out["top_paths"], "path"))
          with open("traffic/weekly/latest.md","w",encoding="utf-8") as f: f.write("\n".join(md)+"\n")

          one = f"Week {out['week_start']}–{out['week_end']}: Views {out['views_count']} (avg {avV}/day), Uniques {out['views_uniques']}; Clones {out['clones_count']} (avg {avC}/day), Uniques {out['clones_uniques']}"
          with open("traffic/weekly/summary.txt","w",encoding="utf-8") as f: f.write(one+"\n")

          with open("traffic/weekly/latest.csv","w",newline="",encoding="utf-8") as f:
              w = csv.writer(f)
              w.writerow(["repo","week_start","week_end","views_count","views_uniques","clones_count","clones_uniques","avg_views_per_day","avg_clones_per_day"])
              w.writerow([out["repo"], out["week_start"], out["week_end"], out["views_count"], out["views_uniques"], out["clones_count"], out["clones_uniques"], avV, avC])
          with open("traffic/weekly/top_paths.csv","w",newline="",encoding="utf-8") as f:
              w = csv.writer(f); w.writerow(["path","count","uniques"])
              for x in out["top_paths"][:10]: w.writerow([x["path"], x["count"], x["uniques"]])
          with open("traffic/weekly/top_referrers.csv","w",newline="",encoding="utf-8") as f:
              w = csv.writer(f); w.writerow(["referrer","count","uniques"])
              for x in out["top_referrers"][:10]: w.writerow([x["referrer"], x["count"], x["uniques"]])
          PY

      - name: Commit weekly aggregate and wrap artifacts
        if: ${{ github.event_name == 'workflow_dispatch' || steps.dow.outputs.fri == 'true' }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add traffic/weekly/**
          git commit -m "traffic: weekly aggregate + wrap artifacts" || echo "No changes to commit"
          git push
